---
title: "Spread tweets"
output: html_document
params:
    dataset_name : "xxxxxxxxxx"       # Nombre del dataset
    base_title : "xxxxxxxxxxxx"       # Prefijo del título principal de las gráficas
    min_followers_influencers: 100000 # Mínimo de followers de un perfil para ser etiquetado
    time_zone: "Europe/Berlin"        # Huso horario
    zoom: FALSE                        # (TRUE/FALSE) TRUE si se desea hacer zoom 
    date_ini_zoom: "YYYY-MM-DD"       # (Solo si zoom es TRUE) Fecha de inicio del zoom, formato YYYY-MM-DD 
    date_end_zoom: "YYYY-MM-DD"       # (Solo si zoom es TRUE) Fecha de inicio del zoom, formato YYYY-MM-DD 
---

```{r setup, 	echo = TRUE,message = FALSE,	warning = FALSE,include=FALSE, cache = FALSE}

require("knitr")
## setting working directory
opts_knit$set(root.dir = "./")
```

## Entorno de trabajo

Estos notebooks trabajan con esta estructura de directorios

    dir_raiz ----+-----data      # Se guardan los datos, cada dataset en un directorio independiente
                 |
                 +-----keys      # se guardan los ficheros con las claves de acceso. 
                 |
                 +-----notebooks # Se guardan los notebooh en R
                 

## Ciclo de análisis: Visualizar propagación temporal

Hay dos maneras de abordar la visualización de la propagación temporal:

-   **Simplificada**: una vez bajados los datos se puede visualizar directamente la propagación. Hay alguna gráfica que no se podrá realizar. Para trabajar en este modo, el parámetro ARS estará a FALSE (**ARS = FALSE)**
-   **Ciclo completo** : Una descargados los datos se procederá a su análisis de red. Esta moralidad permite ver la propagación según los distintos grupos que han participado y que han sido detectados por el análisis de red. Para trabajar en este modo, el parámetro ARS estará a TRUE (**ARS = TRUE)**

### Ciclo simplificado

Es sencillo y rápido. En solo dos pasos podemos averiguar aspectos importantes de la propagación

![Ciclo Análisis simplificado](https://github.com/congosto/congosto.github.io/raw/master/ciclo_basico_visualizacion.JPG)

### Ciclo completo:

Es más elaborado pero permite un análisis en profundidad de la propagación

![Ciclo Análisis completo](https://github.com/congosto/congosto.github.io/raw/master/ciclo_ARS_visualizacion.JPG)

Requiere haber realizado los pasos previos:

-   Generar un fichero gdf con las relaciones de RTs para Gephi mediante el notebook csv2gdf.Rmd
-   Generar un grafo con Gephi y exportar su tabla de datos
-   Clasificar los tweets con el notebook classify_tweets.Rmd

### Visualizaciones disponibles

Las visualizaciones disponibles son:

-   **Summary**: Diagrama de barras con los distintos tipos de tweets
-   **Tweets vs. reach**: una gráfica de doble escala para representar la proporción entre los tweets y el alcance (reach). Adicionalmente, etiqueta a los perfiles que se definen como influencers con el parámetro **min_followers_influencers**
-   **Tweets vs. Rts**: una gráfica de doble escala que representa la proporción entre tweets y retweets
-   **Tweets by lang**: un line chart con la propagación según los idiomas utilizados
-   **Tweets by. Hashtags**: columnas apiladas con la propagación según los hashtags encontradoscon más frecuencia
-   **cumulative site mentions**: Propagación temporal de los sitios web más referenciados
-   **Tweets by comumunity** (solo en ciclo completo): columnas apiladas con la propagación por comunidades
-   **Locations by group** (solo en ciclo completo): nube de palabras de la localización declarada de los autores de los tweets por comunidad
-   **Most frequent words by group** (solo en ciclo completo): nube de palabras de los textos de los tweets por comunidad

Algunas las gráficas están realizadas con una función que permite hacer acotaciones en el tiempo para hacer zoom en periodos específicos.

## Librerías

```{r libraries, message=FALSE, warning=FALSE, include=FALSE}

if(!"tidyverse" %in% installed.packages()) {install.packages("tidyverse")}
if(!"lubridate" %in% installed.packages()) {install.packages("lubridate")}
if(!"ggrepel" %in% installed.packages()) {install.packages("ggrepel")}
if(!"scales" %in% installed.packages()) {install.packages("scales")}
if(!"tidytext" %in% installed.packages()) {install.packages("tidytext")}
if(!"tm" %in% installed.packages()) {install.packages("tm")}
if(!"ggwordcloud" %in% installed.packages()) {install.packages("ggwordcloud")}
if(!"RColorBrewer" %in% installed.packages()) {install.packages("RColorBrewer")}
if(!"ggh4x" %in% installed.packages()) {install.packages("ggh4x")}
if(!"svDialogs" %in% installed.packages()) {install.packages("svDialogs")}
library(svDialogs)
library(tidyverse)       # Suite para datos y gráficos
library(lubridate)       # Tratamiento de fechas
library(ggrepel)         # Ubicación no solapada de textos
library(scales)          # Escalas
library(tidytext)        # Para manejos de textos
library(tm)              # Para manejos de textos
library(ggwordcloud)     # Para crear una nube de palabras
library(RColorBrewer)    # Paleta de colores
library(ggh4x)           # Color en las facetas
library(svDialogs)       # Cuadros de diálogo y formularios
locale(date_names = "en", date_format = "%AD", time_format = "%AT",
  decimal_mark = ".", grouping_mark = ",", tz = "Europe/Berlin",
  encoding = "UTF-8", asciify = FALSE)
Sys.setlocale(category = "LC_ALL", locale = "english")

```

## Importamos funciones

```{r functions, include=FALSE}
source("share_functions.R")                   # Funciones generales
source("share_functions_viz.R")               # Funciones generales de visualización
source("share_functions_spread_tweets.R")     # Funciones de visualización del cuaderno
```

## Entorno por defecto

```{r environment, include=FALSE}
## Entorno por defecto. No tocar salvo que se quiera usar otro entorno
# Guardamos los parámetros
dataset_name <- params$dataset_name         # Nombre del dataset
base_title <- params$base_title             # Prefijo del título principal de las gráficas
min_followers_influencers <- params$min_followers_influencers # Mínimo de followers de un perfil para ser etiquetado
time_zone <-  params$time_zone              # Huso horario
# Gestionamos el entorno de directorios
data_path <- paste0("../datos/", dataset_name, "/") # Directorio de datos
img_path <- paste0(data_path,"/images/" )
base_name_file_img <- dataset_name                       # Prefijo de las imágenes
max_langs <- 11
max_hashtags <- 14
if(file.exists(paste0(data_path, dataset_name, "_classified.csv"))){
  # Hay ciclo completo
  name_file_in <- paste0(data_path,dataset_name,"_classified.csv")
  name_file_communities <- paste0(data_path,dataset_name,"_communities.csv")
  ARS <- TRUE
}else{
  if(file.exists(paste0(data_path, dataset_name, ".csv"))){
    # Ciclo simplificado
    name_file_in <- paste0(data_path,dataset_name,".csv")
    ARS = FALSE
  }else{
    stop("dateset file does not exist")
  }
}
if(file.exists(img_path)) {
 cat(paste(img_path,"already exists"))
} else {
 dir.create(img_path)
 cat(paste(img_path,"created"))
 options(svDialogs.rstudio = TRUE)
}
```

## Leemos el dataset

```{r read_data, include=FALSE}
if(ARS == TRUE) {
  # se ha realizado análisis de red, tenemos los tweets clasificados
  tweets <- read_csv(
    name_file_in,
    col_names = TRUE,
    cols_only(
      date = col_datetime(), 
      author = col_character(),
      text = col_character(),
      followers  = col_number(),
      location = col_character(),
      name = col_character(),
      description = col_character(),
      urls = col_character(),
      url_media = col_character(),
      type_media = col_character(),
      relation = col_character(),
      user_retweeted = col_character(),
      user_replied = col_character(),  
      first_HT = col_character(),
      lang = col_character(),
      retweet_count = col_number(),
      reply_count = col_number(),
      quote_count = col_number(),
      favorite_count = col_number(),
      community = col_character()
    )
  )
  communities <- read_csv(
  name_file_communities,
  col_names = TRUE,
  cols_only(
    community = col_character(), 
    name_community = col_character(),
    color  = col_character())
) 
}else {
   # No se ha realizado análisis de red. Leemos los tweets sin clasificar
   tweets <- read_csv(
     name_file_in,
     col_names = TRUE,
     cols_only(
      date = col_datetime(), 
      author = col_character(),
      text = col_character(),
      followers  = col_number(),
      location = col_character(),
      name = col_character(),
      description = col_character(),
      urls = col_character(),
      url_media = col_character(),
      type_media = col_character(),
      relation = col_character(),
      user_retweeted = col_character(),
      user_replied = col_character(),
      first_HT = col_character(),
      lang = col_character(),
      retweet_count = col_number(),
      reply_count = col_number(),
      quote_count = col_number(),
      favorite_count = col_number()
     )
   )
 }
max_date <- max(tweets$date)
min_date <- min(tweets$date)
num_days <- as.numeric(difftime(max_date ,min_date , units = c("days")))
slot_time <- ifelse(num_days <= 15, "hour", "day")
```

## Adaptamos a la zona horaria y redondeamos por slot time

```{r set_time, include=FALSE}
# Redondeamos por slot time
tweets_df <- tweets %>%
  mutate(date = as.POSIXct(floor_date(lubridate::with_tz(date, time_zone),"sec"))) %>%
  mutate(slot_time = as.POSIXct(floor_date(date,slot_time))) %>%
  mutate(relation_ext = ifelse(is.na(relation) | relation == "None","original", relation))  %>%
  arrange(date)
# Ordenamos las relaciones 
order_relation <- c("original", "quoted", "reply", "RT")
tweets_df$relation_ext <- factor(tweets_df$relation_ext,levels = order_relation )
color_relation <- c("RT"="purple", "reply"="steelblue4", "quoted"="seagreen4", "original" = "red4")
# Calculamos el pico de tweets del slot de tiempo para dimensionar el eje Y de las gráficas
tweet_peak <- tweets_df %>%
  group_by(slot_time) %>%
  summarise(
     tweet_peak =n(),
     .group = "drop"
  ) %>%
  ungroup() %>%
  arrange(desc(tweet_peak)) %>%
  select(tweet_peak) %>%
  top_n(1) %>%
  as.integer()
```

## Resumen

```{r resumen, echo=FALSE, fig.height=5, fig.width=9, message=FALSE, warning=FALSE, paged.print=FALSE}
p <- Summary_tweets(tweets_df)
print(p)
# Salvamos la gráfica en un archivo
ggsave(paste0(img_path,base_name_file_img,"_summary.png"))
```

## Tweets vs. reach

Gráfica de doble escala para representar la proporción de tweets publicados y alcance obtenido. Estas variables tienen distinto orden de magnitud y por eso se representan con un eje Y doble.

Adicionalmente se etiquetan los perfilen que estén en el rango definido como influencers con el parámetro **min_followers_influencers**. Este parámetro se adecuará al alcance de la gráfica. Si no aparece ningún perfil puede se debido a dos motivos:

-   El valor del parámetro es muy alto y no hay perfiles con ese número de seguidores

-   El parámetro es muy bajo y hay tantos perfiles que cumplen la condición que no se Hay que tener en cuenta:

-   Si no aparece nugún perfik

### Periodo total tweets_vs_reach

```{r tweets_reach_total, echo=FALSE, fig.height=5, fig.width=9, message=FALSE, warning=FALSE, paged.print=FALSE}
# Llamamos a la función tweets_vs_reach
p <- tweets_vs_reach(tweets_df , "total",  min_date, max_date ) 
print(p)
# Salvamos la gráfica en un archivo
ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_reach_total.png"))

```

### Zoom tweets_vs_reach

```{r tweets_reach_zoom, echo=FALSE, fig.height=5, fig.width=9, message=FALSE, warning=FALSE, paged.print=FALSE}
if(params$zoom) {
  # Llamamos a la función tweets_vs_reach
  p <- tweets_vs_reach(tweets_df , "zoom", params$date_ini_zoom, params$date_end_zoom)
  print(p)
  # Salvamos la gráfica en un archivo
  ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_reach_zoom.png"))
}
```

## Tweets vs. RTs

### Periodo total tweets-RTs

```{r tweets_vs_RTs_total, echo=FALSE, fig.height=5, fig.width=9, message=FALSE, warning=FALSE, paged.print=FALSE}
# Llamamos a la función tweets_vs_RTs
p <- tweets_vs_RTs(tweets_df , "total",  min_date, max_date) 
print(p)
# Salvamos la gráfica en un archivo
ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_RT_total.png"))

```

### Zoom tweets_vs_RTs

```{r tweets_vs_RTs_zoom, echo=FALSE, fig.height=5, fig.width=9, message=FALSE, warning=FALSE, paged.print=FALSE}
if(params$zoom) {
  # Llamamos a la función tweets_vs_RTs
  p <- tweets_vs_RTs(tweets_df , "zoom",  params$date_ini_zoom, params$date_end_zoom) 
  print(p)
  # Salvamos la gráfica en un archivo
  ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_RT_zoom.png"))
}
```

## Tweets by lang

-   Se limita el número de idiomas a ocho y se le añade cuatro colores de idioma indefinido. Puede ser suficiente en el ámbito europeo-americano e insuficientes para los lenguajes de oriente. Siempre hay la opción de generar manualmente los colores de los idiomas.

8 idiomas máximo más los indefinidos.

Colores por defecto:

-   [es #FF0000 RGB(255,0,0)]{style="color:#FF0000"}
-   [ca #FFFF00 RGB(255,255,0)]{style="color:#FFFF00"}
-   [en #19C3FF RGB(25,195,255)]{style="color:#19C3FF"}
-   [fr #0070C0 RGB(0,112,192)]{style="color:#0070C0"}
-   [de #005426 RGB(0,84,38)]{style="color:#005426"}
-   [pt #FF9933 RGB(255,153,51)]{style="color:#FF9933"}
-   [it #00B050 RGB(0,176,80)]{style="color:#00B050"}
-   [und #808080 RGB(128,128,128)]{style="color:#808080"}
-   [qme #808080(128,128,128)]{style="color:#808080"}
-   [zxx #808080(128,128,128)]{style="color:#808080"}
-   [qht #808080(128,128,128)]{style="color:#808080"}

### Periodo total tweets-lang

```{r tweets_by_lang_total, echo=FALSE, fig.height=5, fig.width=9, message=FALSE, warning=FALSE, paged.print=FALSE}
# Llamamos a la función tweets_by_lang
p <- tweets_by_lang(tweets_df , "total",   min_date, max_date) 
print(p)
# Salvamos la gráfica en un archivo
ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_lang_total.png"))
```

### Zoom tweets-lang

```{r tweets_by_lang_zoom, echo=FALSE, fig.height=5, fig.width=9, message=FALSE, warning=FALSE, paged.print=FALSE}
if(params$zoom) {
  # Llamamos a la función tweets_by_lang
  p <- tweets_by_lang(tweets_df , "zoom",  params$date_ini_zoom, params$date_end_zoom) 
  print(p)
  # Salvamos la gráfica en un archivo
  ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_lang_zoom.png"))
}
```

## Tweets slot time by hashtag

-   Se limita el número de hashtags a catorce, cifra que creo que es suficiente en la mayoría de los casos.

-   Por compatibilidad con el análisis de ARS, se han elegido los ocho colores que Gephi asigna por defecto como lo primeros ocho colores y se han añadido seis más hasta completar los catorce.

![](./colores_defecto_gephi.PNG)

14 hashtags máximo.

Colores por defecto:

-   [#CC66FF RGB(204,102,255)]{style="color:#CC66FF"}
-   [#92D050 RGB(146,208,80)]{style="color:#92D050"}
-   [#00B0F0 RGB(0,176,240)]{style="color:#00B0F0"}
-   [#404040 RGB(64,64,64)]{style="color:#404040"}
-   [#FF9900 RGB(255,153,0)]{style="color:#FF9900"}
-   [#FF5050 RGB(255,80,80)]{style="color:#FF5050"}
-   [#00D67F RGB(0,214,127)]{style="color:#00D67F"}
-   [#F8CBAD RGB(248,203,173)]{style="color:#F8CBAD"}
-   [#8A2E00 RGB(138,46,0)]{style="color:#8A2E00"}
-   [#993366 RGB(153,51,102)]{style="color:#993366"}
-   [#0033CC RGB(0,51,204)]{style="color:#0033CC"}
-   [#008E55 RGB(0,142,85)]{style="color:#008E55"}
-   [#45682D RGB(69,104,45)]{style="color:#45682D"}
-   [#702500 RGB(112,37,0)]{style="color:#702500"}

### Periodo total tweets-hashtags

```{r tweets_by_HT_total, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width=9, fig.height=5}
# Llamamos a la función tweets_by_lang
p <- tweets_by_HT(tweets_df , "total", min_date, max_date) 
print(p)
# Salvamos la gráfica en un archivo
ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_hashtags_total.png"))
```

### Zoom tweets-hashtags

```{r tweets_by_HT_zoom, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width=9, fig.height=5}
if(params$zoom) {
  # Llamamos a la función tweets_by_lang
  p <- tweets_by_HT(tweets_df , "zoom",  params$date_ini_zoom, params$date_end_zoom) 
  print(p)
  # Salvamos la gráfica en un archivo
  ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_hashtags_zoom.png"))
}
```

## Tweets acumulados por sitio

```{r spread_urls, echo=FALSE, fig.height=6, fig.width=11, message=FALSE, warning=FALSE, paged.print=FALSE}
# Llamamos a la función accumulated_sites
p <- accumulated_sites(tweets_df, min_date, max_date)
print(p)
# Salvamos la gráfica en un archivo
ggsave(filename = paste0(img_path,base_name_file_img,"_cumulative_sites.png"))

```

## Tweets by community

Los siguientes scripts visualizan la evolución temporal con ARS. **Solo se ejecutan si el parámetro ARS = TRUE**

Requiere haber realizado los pasos previos:

-   Generar un fichero gdf con las relaciones de Rts para Gephi mediante el notebook csv2gdf.Rmd
-   Generar un grafo con Gephi y exportar su tabla de datos
-   Clasificar los tweets con el notebook classify_tweets.Rmd

Las imágenes resultantes se almacenan en un subdirectorio del experimento llamado.

![ciclo Análisis ARS: Evolución temporal con AR](https://github.com/congosto/congosto.github.io/raw/master/ciclo_ARS_spread.jpg)

### Periodo total tweets-community

```{r tweets_by_community_total, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width=9, fig.height=5}
if(ARS == TRUE) {
  # Llamamos a la función tweets_by_community
  p <- tweets_by_community(tweets_df , "total", min_date, max_date, communities) 
  print(p)
  # Salvamos la gráfica en un archivo
  ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_group_total.png"))
}

```

### Zoom tweets-community

```{r tweets_by_community_zoom, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width=9, fig.height=5}
if(ARS & params$zoom) {
  # Llamamos a la función tweets_vs_RTs
  p <- tweets_by_community(tweets_df , "zoom", params$date_ini_zoom, params$date_end_zoom, communities )
  print(p)
  # Salvamos la gráfica en un archivo
  ggsave(paste0(img_path,base_name_file_img,"_tweets_vs_group_zoom.png"))
}
```

# Origen de los tweets por comunidades

```{r origen_tweets_by_community, echo=FALSE, fig.height=10, fig.width=9, message=FALSE, warning=FALSE}
if(ARS) {
  p <-location_users_by_community(tweets_df, communities)
  print(p)
  # Salvamos la gráfica en un archivo
  ggsave(paste0(img_path,base_name_file_img,"_locations_by_group.png"))
}
```

# Contenido de los tweets por comunidades

```{r contenido_tweets_by_community, echo=FALSE, fig.height=10, fig.width=9, message=FALSE, warning=FALSE}
if(ARS) {
  p <-words_frequency_by_community(tweets_df, communities)
  print(p)
  # Salvamos la gráfica en un archivo
  ggsave(paste0(img_path,base_name_file_img,"_words_frequency_by_group.png"))
}
```
